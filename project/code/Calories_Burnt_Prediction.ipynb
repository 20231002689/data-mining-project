{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7Jv1vVwu4h7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and perform initial exploration to understand its structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z0rnikTGvJ3a",
    "outputId": "c36aa908-5706-4a12-8abe-1d66d65c921d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/data mining/project/dataset/calories.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9kFyBl2vKdB",
    "outputId": "815af460-5353-4c7b-f3fd-3fb312af7318"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmND0J98vLsT",
    "outputId": "c1fad436-4f84-496f-a3f5-10f11294a43b"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "O9QAqdWgvO_6",
    "outputId": "ecce7aaf-dedd-4b86-da7c-1aec1107907a"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User_ID is a unique identifier and does not contribute to the regression task\n",
    "df=df.drop(columns='User_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "aTmNlhhSvQ5X",
    "outputId": "0fc1b4bc-7610-4d9a-90f7-b90c01715675"
   },
   "outputs": [],
   "source": [
    "#Scatterplot of height and weight\n",
    "sns.scatterplot(x='Height', y='Weight', data=df)\n",
    "plt.savefig('Height and Weight scatter_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "x1CG4kM3xJou",
    "outputId": "6bcc8cf1-0fda-4400-91f4-7a22bd15fa18"
   },
   "outputs": [],
   "source": [
    "# Select 'Age', 'Height', 'Weight', 'Duration' as features to study the scatterplot distribution of Calories\n",
    "features = ['Age', 'Height', 'Weight', 'Duration']\n",
    "\n",
    "plt.subplots(figsize=(15, 10))\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    x = df.sample(1000)\n",
    "    sns.scatterplot(x=col, y='Calories', data=x)\n",
    "    plt.title(f'Scatter plot of {col} vs Calories')\n",
    "    plt.xlabel(col)\n",
    "plt.savefig('scatter_plots with Calories.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "id": "Yz8m04CdvTNy",
    "outputId": "f03d53aa-9769-4955-fdec-64041c97ef1a"
   },
   "outputs": [],
   "source": [
    "# Plotting histograms containing kernel density estimation (KDE) curves\n",
    "features = df.select_dtypes(include='float').columns\n",
    "\n",
    "plt.subplots(figsize=(15, 10))\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.histplot(df[col],kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "plt.savefig('hist.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sL7YDfgZvURT",
    "outputId": "d9227b62-bfc2-4aa3-ac08-cc3410df2597"
   },
   "outputs": [],
   "source": [
    "df['Gender']=df['Gender'].map({'male':0,'female':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix heatmap\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig('Correlation Heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wKJsOMkvXdT",
    "outputId": "9d62a593-e0e3-470d-9eb9-8fd01f8639db"
   },
   "outputs": [],
   "source": [
    "# Divide the dataset\n",
    "X = df.drop(['Calories'], axis=1)\n",
    "y = df['Calories']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, X_scaled.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMEdfLU6vYd7"
   },
   "outputs": [],
   "source": [
    "# Normalizing the features for stable and fast training.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building Hyperparameter tuning Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8pT5mEYvZbz",
    "outputId": "b2ea6097-c8ff-49c4-c20c-b1a62ce40415"
   },
   "outputs": [],
   "source": [
    "# Target model\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'Neural Network': MLPRegressor(max_iter=2000, random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "    'Lasso': {'alpha': [0.1, 1.0, 10.0]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5], 'learning_rate': [0.01, 0.1, 0.3]},\n",
    "    'Neural Network': {'hidden_layer_sizes': [(64, 32), (128, 64), (100,)], 'learning_rate_init': [0.001, 0.01]}\n",
    "}\n",
    "\n",
    "# Dictionary to store trained models for plotting\n",
    "fitted_models = {}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if name in param_grids:\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"{name} Best Parameters: {best_params}\")\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "    # Store the fitted model\n",
    "    fitted_models[name] = best_model\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_mse = -cross_val_score(best_model, X_train, X_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    cv_r2 = cross_val_score(best_model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    \n",
    "    results[name] = {'MSE': mse, 'RMSE': rmse, 'R²': r2, 'CV MSE': cv_mse, 'CV R²': cv_r2}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons between different models and visualisation of feature significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values for each model\n",
    "for name, model in fitted_models.items():\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5, label='Actual vs. Predicted')\n",
    "    \n",
    "    # Add diagonal line (perfect prediction line: y=x)\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction (y=x)')\n",
    "    \n",
    "    plt.xlabel('Actual Calories')\n",
    "    plt.ylabel('Predicted Calories')\n",
    "    plt.title(f'Actual vs. Predicted Calories: {name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'figures/actual_vs_predicted_{name.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks and random forests significantly outperform other models, linear class models work less well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RMSE\n",
    "results_df.index = results_df.index.astype(str)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y=results_df['RMSE'])\n",
    "plt.title('Model Comparison: RMSE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.savefig('Model_Comparison_RMSE.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost has a relatively high RMSE  \n",
    "Possible problem:  \n",
    "Learning rate is too high or too low: Improperly set learning_rate may cause gradient descent to fail to find an optimal solution to the loss function.For example, SGDRegressor defaults to a learning rate of 0.01, which may not be appropriate for your data.  \n",
    "Insufficient iterations: max_iter (maximum number of iterations) is set too low, which may result in the model not converging.   \n",
    "Data not properly normalised: gradient descent is sensitive to feature scale.If the features are not correctly normalised (despite StandardScaler being used in your code), this may lead to unstable optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize R²\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y=results_df['R²'])\n",
    "plt.title('Model Comparison: R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('R² Score')\n",
    "plt.savefig('Model_Comparison_R² Score.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, Random forests, XGBoost, all have higher R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of feature importance\n",
    "for name in ['Random Forest', 'XGBoost']:\n",
    "    model = models[name]\n",
    "    model.fit(X_train, y_train)\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title(f'Feature Importance: {name}')\n",
    "    plt.savefig(f'Feature_Importance_{name}.png')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration and Heart_Rate contribute the most to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
